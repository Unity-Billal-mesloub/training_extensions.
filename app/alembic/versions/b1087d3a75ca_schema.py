"""Schema

Revision ID: b1087d3a75ca
Revises:
Create Date: 2025-07-28 11:50:32.455501

"""

from collections.abc import Sequence
from uuid import uuid4

import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision: str = "b1087d3a75ca"
down_revision: str | Sequence[str] | None = None
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    sources_table = op.create_table(
        "sources",
        sa.Column("id", sa.Text(), nullable=False),
        sa.Column("source_type", sa.String(length=50), nullable=False),
        sa.Column("config_data", sa.JSON(), nullable=False),
        sa.Column("created_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.Column("updated_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    sinks_table = op.create_table(
        "sinks",
        sa.Column("id", sa.Text(), nullable=False),
        sa.Column("sink_type", sa.String(length=50), nullable=False),
        sa.Column("rate_limit", sa.Float(), nullable=True),
        sa.Column("config_data", sa.JSON(), nullable=False),
        sa.Column("output_formats", sa.JSON(), nullable=False),
        sa.Column("created_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.Column("updated_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    pipelines_table = op.create_table(
        "pipelines",
        sa.Column("id", sa.Text(), nullable=False),
        sa.Column("source_id", sa.Text(), nullable=True),
        sa.Column("sink_id", sa.Text(), nullable=True),
        sa.Column("name", sa.String(length=255), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("is_running", sa.Boolean(), nullable=False),
        sa.Column("created_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.Column("updated_at", sa.DateTime(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
        sa.ForeignKeyConstraint(["sink_id"], ["sinks.id"], ondelete="SET NULL"),
        sa.ForeignKeyConstraint(["source_id"], ["sources.id"], ondelete="SET NULL"),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("name"),
    )
    # ### end Alembic commands ###
    source_id = str(uuid4())
    op.bulk_insert(
        sources_table,
        [{"id": source_id, "source_type": "video_file", "config_data": {"video_path": "data/media/video.mp4"}}],
    )
    sink_id = str(uuid4())
    op.bulk_insert(
        sinks_table,
        [
            {
                "id": sink_id,
                "sink_type": "folder",
                "rate_limit": 0.2,
                "output_formats": ["image_original", "image_with_predictions", "predictions"],
                "config_data": {"folder_path": "data/output"},
            }
        ],
    )
    op.bulk_insert(
        pipelines_table,
        [
            {
                "id": str(uuid4()),
                "source_id": source_id,
                "sink_id": sink_id,
                "name": "Video Processing Pipeline",
                "description": "Pipeline for processing video files",
                "is_running": True,
            }
        ],
    )


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("pipelines")
    op.drop_table("sources")
    op.drop_table("sinks")
    # ### end Alembic commands ###
